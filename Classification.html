<!DOCTYPE html>
<html lang="en">
    <!-- This is mostly generated by Claude. I tried to keep the ideas sane though -->
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Effective LLM Classification: An Interview Presentation</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        h1 {
            color: #2c3e50;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
        }
        h2 {
            color: #2980b9;
        }
        .slide {
            margin-bottom: 40px;
            border: 1px solid #ddd;
            padding: 20px;
            border-radius: 5px;
        }
        .pipeline {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }
        .pipeline-step {
            background-color: #3498db;
            color: white;
            padding: 10px;
            margin: 0 5px;
            border-radius: 20px;
        }
        .focus {
            background-color: #2ecc71;
        }
        ul {
            padding-left: 20px;
        }
    </style>
</head>
<body>
    <h1>Effective LLM Classification: An Interview Presentation</h1>

    <div class="slide">
        <h2>1. Effective LLM Classification</h2>
        <p>A comprehensive guide to working with LLMs for classification tasks</p>
        <ul>
            <li>Understanding the LLM pipeline</li>
            <li>Effective prompting techniques</li>
            <li>Structured output formats</li>
            <li>Evaluation and iteration</li>
        </ul>
    </div>

    <div class="slide">
        <h2>2. Simple Prompt-Based Classification</h2>
        <p>Start with a basic LLM and a prompt for classification.</p>
        <div class="pipeline">
            <div class="pipeline-step">Prompt</div>
            <div class="pipeline-step focus">LLM</div>
        </div>
        <ul>
            <li>Quick to implement</li>
            <li>Flexible for various tasks</li>
            <li>May have inconsistent results</li>
            <li>Lacks quality control</li>
        </ul>
    </div>

    <div class="slide">
        <h2>3. Evaluation Against Dataset</h2>
        <p>Introduce a dataset to evaluate LLM performance.</p>
        <div class="pipeline">
            <div class="pipeline-step">Prompt</div>
            <div class="pipeline-step">LLM</div>
            <div class="pipeline-step focus">Evaluate</div>
        </div>
        <ul>
            <li>Quantifiable performance metrics</li>
            <li>Ability to detect inconsistencies</li>
            <li>Potential mismatch with real-world data</li>
            <li>Dataset maintenance overhead</li>
        </ul>
    </div>

    <div class="slide">
        <h2>4. Iteration and Improvement</h2>
        <p>Establish a cycle of refining prompts and re-evaluating.</p>
        <div class="pipeline">
            <div class="pipeline-step">Prompt</div>
            <div class="pipeline-step">LLM</div>
            <div class="pipeline-step">Evaluate</div>
            <div class="pipeline-step focus">Iterate</div>
        </div>
        <ul>
            <li>Continuous performance improvement</li>
            <li>Adaptability to specific use cases</li>
            <li>Time-consuming process</li>
            <li>Risk of overfitting to test set</li>
        </ul>
    </div>

    <div class="slide">
        <h2>5. Data Preprocessing</h2>
        <p>Implement data cleaning and standardization steps.</p>
        <div class="pipeline">
            <div class="pipeline-step focus">Preprocess</div>
            <div class="pipeline-step">Prompt</div>
            <div class="pipeline-step">LLM</div>
            <div class="pipeline-step">Evaluate</div>
            <div class="pipeline-step">Iterate</div>
        </div>
        <ul>
            <li>More consistent input format</li>
            <li>Reduced noise in data</li>
            <li>Potential loss of important information</li>
            <li>Increased pipeline complexity</li>
        </ul>
    </div>

    <div class="slide">
        <h2>6. Augment with Retrieval</h2>
        <p>Fetch relevant data to enhance the prompt with context.</p>
        <div class="pipeline">
            <div class="pipeline-step">Preprocess</div>
            <div class="pipeline-step focus">Retrieve</div>
            <div class="pipeline-step">Prompt</div>
            <div class="pipeline-step">LLM</div>
            <div class="pipeline-step">Evaluate</div>
            <div class="pipeline-step">Iterate</div>
        </div>
        <ul>
            <li>Enhanced context for better decision-making</li>
            <li>Improved handling of edge cases</li>
            <li>Increased latency</li>
            <li>Potential for irrelevant information</li>
        </ul>
    </div>

    <div class="slide">
        <h2>7. Effective Prompting: Expert Framing</h2>
        <p>Boost performance by framing the LLM as an expert</p>
        <ul>
            <li>Start with: 'You are an expert in [task_name]'</li>
            <li>Describe relevant qualifications or experience</li>
            <li>Example: 'You are an expert linguist with 20 years of experience in sentiment analysis'</li>
        </ul>
    </div>

    <div class="slide">
        <h2>8. Effective Prompting: Example-Driven</h2>
        <p>Show the LLM exactly what you want</p>
        <ul>
            <li>Provide a concrete example of the desired output</li>
            <li>Use the same format and style you expect in the result</li>
            <li>Include edge cases or difficult examples if relevant</li>
        </ul>
    </div>

    <div class="slide">
        <h2>9. Structured Output: XML/HTML</h2>
        <p>Leverage LLM's familiarity with markup languages</p>
        <ul>
            <li>Use XML or HTML tags to structure the output</li>
            <li>Example: &lt;classification&gt;&lt;category&gt;Positive&lt;/category&gt;&lt;confidence&gt;8&lt;/confidence&gt;&lt;/classification&gt;</li>
            <li>LLMs have extensive training on these formats due to web data</li>
            <li>Use simple integer values (1-10) for numeric data</li>
        </ul>
    </div>

    <div class="slide">
        <h2>10. Structured Output: JSON</h2>
        <p>Utilize JSON for easy parsing and processing</p>
        <ul>
            <li>Request output in JSON format</li>
            <li>Example: {'category': 'Positive', 'confidence': 8}</li>
            <li>Ideal for integration with downstream processes</li>
            <li>Note: Complex JSON can be challenging for LLMs</li>
            <li>Minimize whitespace to reduce token count</li>
            <li>For complex structures, consider providing a template</li>
        </ul>
    </div>

    <div class="slide">
        <h2>11. Structured Output: Markdown Tables</h2>
        <p>Use Markdown for human-readable structured output</p>
        <ul>
            <li>Request results in a Markdown table format</li>
            <li>Example:</li>
            <li>| Category | Confidence |<br>|-----------|------------|<br>| Positive  | 8          |</li>
            <li>Balances machine-readability and human-readability</li>
            <li>Use simple integer values (1-10) for numeric data</li>
        </ul>
    </div>

    <div class="slide">
        <h2>12. Prompt Engineering Best Practices</h2>
        <p>Key techniques for effective LLM prompts</p>
        <ul>
            <li>Be specific and clear in instructions</li>
            <li>Use consistent formatting</li>
            <li>Provide relevant context</li>
            <li>Incorporate few-shot learning examples</li>
            <li>Encourage step-by-step reasoning (Chain of Thought)</li>
        </ul>
    </div>

    <div class="slide">
        <h2>13. ReAct Framework</h2>
        <p>Reasoning and Acting in classification prompts</p>
        <ul>
            <li>Break down complex tasks into steps</li>
            <li>Alternate between reasoning and action steps</li>
            <li>Allow for self-correction and refinement</li>
            <li>Example: 'Reason about the sentiment, then classify, then explain your decision'</li>
        </ul>
    </div>

    <div class="slide">
        <h2>14. Evaluation Metrics</h2>
        <p>Key metrics for assessing classification performance</p>
        <ul>
            <li>Accuracy: Overall correctness</li>
            <li>Precision & Recall: Balancing specificity and sensitivity</li>
            <li>F1 Score: Harmonic mean of precision and recall</li>
            <li>Confusion Matrix: Detailed breakdown of predictions</li>
        </ul>
    </div>

    <div class="slide">
        <h2>15. Iterative Improvement</h2>
        <p>Continuously refine your LLM classification system</p>
        <ul>
            <li>Analyze errors to identify patterns</li>
            <li>Refine prompts based on metric insights</li>
            <li>Experiment with different structured output formats</li>
            <li>Regularly update your evaluation dataset</li>
            <li>Consider A/B testing for prompt variations</li>
        </ul>
    </div>

    <div class="slide">
        <h2>16. Putting It All Together</h2>
        <p>A holistic approach to LLM classification</p>
        <ul>
            <li>Combine expert framing, example-driven prompts, and structured outputs</li>
            <li>Continuously evaluate and iterate on your system</li>
            <li>Balance between performance, cost, and latency</li>
            <li>Stay updated on latest LLM developments and techniques</li>
        </ul>
    </div>
</body>
</html>
